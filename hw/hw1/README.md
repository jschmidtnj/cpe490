# Summary of end-to-end arguments in system design

This paper discusses what end-to-end design is in a communication system, and when to use high-level vs. low-level functions to maintain this end-to-end system. In short, end-to-end system design ensures that when the application sends data, the application on the other side of the communication protocol receives that data - thus, the data goes from one end to the other. This system needs to perform some data-integrity check to ensure that the data that was sent was received correctly. There are a number of reasons why the data would be corrupted when it is sent. Bits may be lost when reading a file from a computer, when buffering the file, when transmitting it over the wire in packets, and when it is doing the opposite on the other side. Algorithms and checksums can be used for verifying the accuracy of the data and suggesting to retry if it there is an inconsistency, but then there is the problem of duplicate data sends and timeouts. All of this error checking additionally takes time and energy from the system, and nothing is guaranteed to be perfect every time. Then there is the question of at what abstraction level this computation should be done. Should the error checking occur at the lowest level so that all packets going through the communication system are verified? Or should it be at a higher level, where more latency is introduced but the system would be more flexible, allowing for some applications to perform this error checking and others not? Having the error checking at a lower level will put less overhead on application designers and would lead to increased speeds for the programs that need this error checking, but programs that will need different error checking will have less performance. This is the main question that the paper attempts to solve. The paper argues that an end-to-end design is necessary to ensure that data is sent in a reliable manner between applications in every scenario, but also states that most of this error checking should be done at a higher level. Only the bare minimum, the necessities should be done at the lower levels, giving the flexibility to the applications to perform their own error mitigation strategies. One example the paper describes is end-to-end encryption, whereby only the top application layer is able to decrypt the data being sent over the network. This cutting-edge security technology is only possible with an end-to-end system with minimal computation at lower levels, since the end-to-end encryption is not necessary on applications that don't need it, like file transfer between computers over a closed network. On the opposite end of the spectrum, a Voice over IP (VoIP) system would require very little error checking, since the goal of this system is to provide real-time conversation at the expense of voice quality. Duplicate buffered voice samples and drops in packets are allowed to ensure that the conversation is as close to real-time as possible. Live-streaming video is another example of sacrificing data integrity for speed. So in conclusion, end-to-end systems are necessary to ensure that data is being received at both sides of the application, but error checking should mostly be done at higher levels over the lower ones.
